# -*- coding: utf-8 -*-
"""Single Hyperparameter tuning of neural-network-sarcasm-detection-scikit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yrUi5lcXd3eNaTK7DXl0XhpTDwc7iYNW

# Preamble
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.tree import DecisionTreeClassifier
import re
import nltk
import warnings
from sklearn.exceptions import ConvergenceWarning
stemmer = nltk.SnowballStemmer("english")
from nltk.corpus import stopwords
import string
# %matplotlib inline

sarcasm = pd.read_json('./Sarcasm_Headlines_Dataset.json', lines=True)
sarcasm2 = pd.read_json('./Sarcasm_Headlines_Dataset_v2.json', lines=True)

#from google.colab import drive
#drive.mount('/content/drive')

sarcasm.head()

sarcasm2.head()

sarcasm.info()

"""# Data Normalisation"""

print(sarcasm.isnull().sum())
sarcasm2.isnull().sum()

sarcasm.drop('article_link', axis=1, inplace=True)
sarcasm2.drop('article_link', axis=1, inplace=True)

sarcasm.isnull().sum()

sarcasm.head()

sarcasm2.head()

label_quality = LabelEncoder()

sarcasm['is_sarcastic'] = label_quality.fit_transform(sarcasm['is_sarcastic'])
sarcasm2['is_sarcastic'] = label_quality.fit_transform(sarcasm2['is_sarcastic'])

sarcasm.head(10)

sarcasm2.head()

print(sarcasm['is_sarcastic'].value_counts())
sarcasm2['is_sarcastic'].value_counts()

sns.countplot(sarcasm['is_sarcastic'])
sns.countplot(sarcasm2['is_sarcastic'])

nltk.download('stopwords')
stopword=set(stopwords.words('english'))

def clean(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text = [word for word in text.split(' ') if word not in stopword]
    text=" ".join(text)
    text = [stemmer.stem(word) for word in text.split(' ')]
    text=" ".join(text)
    return text
sarcasm["headline"] = sarcasm["headline"].apply(clean)
sarcasm2["headline"] = sarcasm2["headline"].apply(clean)
print(sarcasm.head())
sarcasm2.head()

# First dataset training
data = sarcasm[["headline", "is_sarcastic"]]
x = np.array(data["headline"])
y = np.array(data["is_sarcastic"])

cv = CountVectorizer()
X = cv.fit_transform(x) # Fit the Data
# print(X.shape)
# print(y.shape)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)


# Second dataset training
data2 = sarcasm2[["headline", "is_sarcastic"]]
x2 = np.array(data2["headline"])
y2 = np.array(data2["is_sarcastic"])

cv2 = CountVectorizer()
X2 = cv2.fit_transform(x2) # Fit the Data

# Dimensions need to match
X2 = X2[:26709, :18833]
y2 = y2[:26709]

X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20, random_state=42)

"""# Neural Network"""

mlp = MLPClassifier(
    hidden_layer_sizes=(50,),
    max_iter=10,
    alpha=1e-4,
    solver="sgd",
    verbose=10,
    random_state=1,
    learning_rate_init=0.1,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp.fit(X_train, y_train)

print("Training set score: %f" % mlp.score(X_train, y_train))
print("Test set score: %f" % mlp.score(X_test, y_test))

mlp2 = MLPClassifier(
        solver= "sgd",
        learning_rate= "constant",
        momentum= 0,
        learning_rate_init= 0.2,
        max_iter=10,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp2.fit(X_train, y_train)

    print("Training set score: %f" % mlp2.score(X_train, y_train))
    print("Test set score: %f" % mlp2.score(X_test, y_test))

mlp3 = MLPClassifier(
    solver= "sgd",
        learning_rate= "constant",
        momentum= 0.9,
        learning_rate_init= 0.2,
        max_iter=10,
        nesterovs_momentum = False,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp3.fit(X_train, y_train)

    print("Training set score: %f" % mlp3.score(X_train, y_train))
    print("Test set score: %f" % mlp3.score(X_test, y_test))

mlp4 = MLPClassifier(
    solver= "sgd",
        learning_rate= "constant",
        momentum= 0.9,
        learning_rate_init= 0.2,
        max_iter=10,
        nesterovs_momentum = True,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp4.fit(X_train, y_train)

print("Training set score: %f" % mlp4.score(X_train, y_train))
print("Test set score: %f" % mlp4.score(X_test, y_test))

mlp5 = MLPClassifier(
   solver= "sgd",
        learning_rate= "invscaling",
        momentum= 0,
        learning_rate_init= 0.2,
        max_iter=10,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp5.fit(X_train, y_train)

    print("Training set score: %f" % mlp5.score(X_train, y_train))
    print("Test set score: %f" % mlp5.score(X_test, y_test))

mlp6 = MLPClassifier(
    solver= "sgd",
        learning_rate= "invscaling",
        momentum= 0.9,
        learning_rate_init= 0.2,
        max_iter=10,
        nesterovs_momentum = True,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp6.fit(X_train, y_train)

    print("Training set score: %f" % mlp6.score(X_train, y_train))
    print("Test set score: %f" % mlp6.score(X_test, y_test))

mlp7 = MLPClassifier(
    solver= "sgd",
        learning_rate= "invscaling",
        momentum= 0.9,
        learning_rate_init= 0.2,
        max_iter=10,
        nesterovs_momentum = False,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp7.fit(X_train, y_train)

    print("Training set score: %f" % mlp7.score(X_train, y_train))
    print("Test set score: %f" % mlp7.score(X_test, y_test))

mlp8 = MLPClassifier(
   solver= "adam",
        #learning_rate= "constant",
        momentum= 0,
        learning_rate_init= 0.01,
        max_iter=10,
        verbose=10,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp8.fit(X_train, y_train)

    print("Training set score: %f" % mlp8.score(X_train, y_train))
    print("Test set score: %f" % mlp8.score(X_test, y_test))

mlp9 = MLPClassifier(
   solver= "adam",
        #learning_rate= "constant",
        #momentum= 0,
        learning_rate_init= 0.01,
        #max_iter=10,
        verbose=True,
)
import warnings
from sklearn.exceptions import ConvergenceWarning

# this example won't converge because of CI's time constraints, so we catch the
# warning and are ignore it here
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
    mlp9.fit(X_train, y_train)

    print("Training set score: %f" % mlp9.score(X_train, y_train))
    print("Test set score: %f" % mlp9.score(X_test, y_test))

pred_mlp = mlp.predict(X_test)
print(classification_report(y_test, pred_mlp))
print(confusion_matrix(y_test, pred_mlp))

pred_mlp = mlp.predict(X_test)
print(classification_report(y_test, pred_mlp))
print(confusion_matrix(y_test, pred_mlp))

pred_mlp2 = mlp2.predict(X_test)
print(classification_report(y_test, pred_mlp2))
print(confusion_matrix(y_test, pred_mlp2))

pred_mlp3 = mlp3.predict(X_test)
print(classification_report(y_test, pred_mlp3))
print(confusion_matrix(y_test, pred_mlp3))

pred_mlp4 = mlp4.predict(X_test)
print(classification_report(y_test, pred_mlp4))
print(confusion_matrix(y_test, pred_mlp4))

pred_mlp5 = mlp5.predict(X_test)
print(classification_report(y_test, pred_mlp5))
print(confusion_matrix(y_test, pred_mlp5))

pred_mlp6 = mlp6.predict(X_test)
print(classification_report(y_test, pred_mlp6))
print(confusion_matrix(y_test, pred_mlp6))

pred_mlp7 = mlp7.predict(X_test)
print(classification_report(y_test, pred_mlp7))
print(confusion_matrix(y_test, pred_mlp7))

pred_mlp8 = mlp8.predict(X_test)
print(classification_report(y_test, pred_mlp8))
print(confusion_matrix(y_test, pred_mlp8))

pred_mlp9 = mlp9.predict(X_test)
print(classification_report(y_test, pred_mlp9))
print(confusion_matrix(y_test, pred_mlp9))

#Training on subset of dataset 1 and Testing on another mutually exlusive subset of dataset 1 
mlpc = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=10000) #500 originally but did not converge
mlpc.fit(X_train, y_train)
pred_mlpc = mlpc.predict(X_test)

#Training on subset of dataset 2 and Testing on another mutually exlusive subset of dataset 2 
mlpc2 = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=10000) #500 originally but did not converge
mlpc2.fit(X_train2, y_train2)
pred_mlpc2 = mlpc2.predict(X_test2)

#Training on subset of dataset 1 and Testing on another mutually exlusive subset of dataset 2 
mlpc3 = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=10000) #500 originally but did not converge
mlpc3.fit(X_train, y_train)
pred_mlpc3 = mlpc3.predict(X_test2)

#Training on dataset 1 and testing on dataset 1
model = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=10000)
model.fit(X_train, y_train)
pred_model = model.predict(X_test)

#Training on dataset 2 and testing on dataset 1 
model2 = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=10000)
model2.fit(X_train2, y_train2)
pred_model2 = model2.predict(X_test)
#print(model2.score(X_test, y_test))

print(classification_report(y_test, pred_mlpc))
print(confusion_matrix(y_test, pred_mlpc))

print(classification_report(y_test, pred_mlpc2))
print(confusion_matrix(y_test, pred_mlpc2))

print(classification_report(y_test2, pred_mlpc3))
print(confusion_matrix(y_test2, pred_mlpc3))

print(classification_report(y_test2, pred_mlpc2))
print(confusion_matrix(y_test2, pred_mlpc2))

print(classification_report(y_test2, pred_model))
print(confusion_matrix(y_test2, pred_model))

print(classification_report(y_test, pred_model2))
print(confusion_matrix(y_test, pred_model2))

"""# Accuracy Scores"""

cm = accuracy_score(y_test, pred_mlp)
print(mlp.score(X_test, y_test))
cm

cm = accuracy_score(y_test, pred_mlp2)
cm

cm = accuracy_score(y_test, pred_mlp3)
cm

cm = accuracy_score(y_test, pred_mlp4)
cm

cm = accuracy_score(y_test, pred_mlp5)
cm

cm = accuracy_score(y_test, pred_mlp6)
cm

cm = accuracy_score(y_test, pred_mlp7)
cm

cm = accuracy_score(y_test, pred_mlp8)
cm

cm = accuracy_score(y_test, pred_mlp9)
cm

"""# Single sentence predictors"""

user = input("Enter a Text: ")
data = cv.transform([user]).toarray()
output = mlpc.predict(data)
if output == 1:
    print('sarcastic')
else: 
    print ('genuine')
